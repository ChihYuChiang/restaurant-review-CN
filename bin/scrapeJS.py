'''
------------------------------------------------------------
Set up webdriver (browser)
------------------------------------------------------------
'''
from selenium import webdriver
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities


#--Set options
#Device capability
def setupDcaps():
    dcaps = DesiredCapabilities.PHANTOMJS
    dcaps['phantomjs.page.settings.loadImages'] = False
    dcaps['phantomjs.page.settings.userAgent'] = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37'
    return dcaps
dcaps = setupDcaps()

#Additional driver options
DOWNLOAD_TIMEOUT = 20
LOG_PATH = 'log/ghostdriver.log'


#--Initiate browser
#Replace with .Firefox(), or with the browser of choice (options could be different)
browser = webdriver.PhantomJS(
    desired_capabilities=dcaps,
    service_log_path=LOG_PATH)
browser.set_page_load_timeout(DOWNLOAD_TIMEOUT)








'''
------------------------------------------------------------
Browse and acquire html - restaurant main page
------------------------------------------------------------
'''
import time
import pandas as pd

#%%
def collectMainPage(shopId):
    #--Targeting a main page url and navigate to that page
    url = 'http://www.dianping.com/shop/' + str(shopId)
    browser.get(url)


    #--Acquire general user rating generated by JS
    #Actions
    webdriver.ActionChains(browser
        ).click(on_element=browser.find_element_by_css_selector('.brief-info > a.icon')
        ).perform()

    #Get HTML
    HTML_generalScore = browser.execute_script('return document.getElementById("shop-score").innerHTML')


    #--Acquire recommended dishes generated by JS
        #Actions
    try:
        webdriver.ActionChains(browser
            ).click(on_element=browser.find_element_by_css_selector('.recommend-name + .J-more')
            ).perform()

        #Get HTML
        HTML_recDish = browser.execute_script('return document.getElementsByClassName("recommend-name")[0].innerHTML')
    except: HTML_recDish = None

    #--Acquire main page + basic info generated by JS
    #Actions
    webdriver.ActionChains(browser
        ).click(on_element=browser.find_element_by_css_selector('.basic-info > a.J-unfold')
        ).perform()

    #Get HTML
    HTML_main = browser.execute_script('return document.documentElement.outerHTML')

    #--Set a timeout between each request
    time.sleep(3)


    #--Return the scraped contents
    return HTML_generalScore, HTML_recDish, HTML_main



HTML_generalScores = []
HTML_recDishes = []

OUTPUT_PATH = '../data/'
shopIds = [93230555, 90404278, 75010650, 6088238, 22303139]
for shopId in shopIds:
    print(shopId)
    HTML_generalScore, HTML_recDish, HTML_main = collectMainPage(shopId)

    with open(OUTPUT_PATH + 'raw/' + str(shopId) + '.html', 'w+', encoding='utf-8') as f:
        f.write(HTML_main)

    HTML_generalScores.append(HTML_generalScore)
    HTML_recDishes.append(HTML_recDish)

df_shopInfo_HTML = pd.DataFrame({
    'shopIds'           : shopIds,
    'HTML_generalScores': HTML_generalScores,
    'HTML_recDishes'    : HTML_recDishes
})

#%%
df_shopInfo_HTML.to_csv(OUTPUT_PATH + 'df_shopInfo_HTML.csv')